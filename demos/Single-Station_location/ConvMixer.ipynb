{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c93954c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#vimport tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee768d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13475, 5000, 3), (13475, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# load data\n",
    "data = np.load('loc/datloc.npy')\n",
    "relative_list = np.load('loc/relativelist.npy')\n",
    "e_stlat = np.load('loc/stlat.npy')\n",
    "e_stlong = np.abs(np.load('loc/stlon.npy'))\n",
    "evlat = np.load('loc/evlat.npy')\n",
    "evlon = np.abs(np.load('loc/evlon.npy'))\n",
    "\n",
    "relative_list[:,0] = e_stlat - evlat\n",
    "relative_list[:,1] = e_stlong - evlon\n",
    "relative_list[:,2] = relative_list[:,2]/1000\n",
    "np.shape(data), np.shape(relative_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a700aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Depth\n",
    "d= relative_list[0:,2]\n",
    "min_d = np.min(d)\n",
    "max_d = np.max(d)\n",
    "normalized_d = (d - min_d) / (max_d - min_d)\n",
    "relative_list3 = np.copy(relative_list)\n",
    "relative_list3[:,2] = normalized_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44bee882",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 128\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04a9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras import constraints\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.keras.layers import DepthwiseConv1D\n",
    "# imports for backwards namespace compatibility\n",
    "# pylint: disable=unused-import\n",
    "# pylint: enable=unused-import\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.util.tf_export import keras_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bf07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout= 0.1\n",
    "def activation_block(x):\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    if dropout != 0.0:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_stem(x, filters: int, patch_size: int):\n",
    "    x = layers.Conv1D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
    "    return activation_block(x)\n",
    "\n",
    "\n",
    "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
    "    # Depthwise convolution.\n",
    "    x0 = x\n",
    "    x = DepthwiseConv1D(kernel_size=kernel_size, padding=\"same\")(x)\n",
    "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
    "\n",
    "    # Pointwise convolution.\n",
    "    x = layers.Conv1D(filters, kernel_size=1)(x)\n",
    "    x = activation_block(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_conv_mixer_256_8(\n",
    "\n",
    "\n",
    "\n",
    "    image_size=5000, filters=512, depth=10, kernel_size=13, patch_size=10, num_classes=3  #\n",
    "    \n",
    "):\n",
    "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
    "    The hyperparameter values are taken from the paper.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input((image_size, 3))\n",
    "    #x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
    "    #x = (inputs)\n",
    "\n",
    "    # Extract patch embeddings.\n",
    "    x = conv_stem(inputs, filters, patch_size)\n",
    "\n",
    "    # ConvMixer blocks.\n",
    "    for _ in range(depth):\n",
    "        x = conv_mixer_block(x, filters, kernel_size)\n",
    "\n",
    "    # Classification block.\n",
    "    x = layers.GlobalAvgPool1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"linear\")(x)\n",
    "\n",
    "    model = tensorflow.keras.Model(inputs, outputs)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6a0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code reference:\n",
    "# https://keras.io/examples/vision/image_classification_with_vision_transformer/.\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "    \n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tensorflow.keras.optimizers.Adam(lr=0.001),\n",
    "        loss= ['mse'],\n",
    "        metrics= ['mse'],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"TX_bestmodelConvMix3.h5\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\",mode='min',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=25, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        data, relative_list3, batch_size=16,validation_split=0.1 ,\n",
    "        epochs=300, shuffle=False,\n",
    "        callbacks=[checkpoint_callback,early_stopping],\n",
    "    )\n",
    "\n",
    "    #model.load_weights(checkpoint_filepath)\n",
    "    #_, accuracy = model.evaluate(test_dataset)\n",
    "    #print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff37903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 12:05:50.864884: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-17 12:05:52.138418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9239 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5000, 3)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 500, 512)     15872       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 500, 512)    2048        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 500, 512)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 500, 512)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " depthwise_conv1d (DepthwiseCon  (None, 500, 512)    7168        ['dropout[0][0]']                \n",
      " v1D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 500, 512)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 500, 512)     0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 500, 512)     0           ['dropout_1[0][0]',              \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 500, 512)     262656      ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 500, 512)    2048        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 500, 512)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 500, 512)     0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " depthwise_conv1d_1 (DepthwiseC  (None, 500, 512)    7168        ['dropout_2[0][0]']              \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 500, 512)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 500, 512)     0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 500, 512)     0           ['dropout_3[0][0]',              \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 500, 512)     262656      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 500, 512)    2048        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 500, 512)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 500, 512)     0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " depthwise_conv1d_2 (DepthwiseC  (None, 500, 512)    7168        ['dropout_4[0][0]']              \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 500, 512)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 500, 512)     0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 500, 512)     0           ['dropout_5[0][0]',              \n",
      "                                                                  'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 500, 512)     262656      ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 500, 512)    2048        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 500, 512)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 500, 512)     0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " depthwise_conv1d_3 (DepthwiseC  (None, 500, 512)    7168        ['dropout_6[0][0]']              \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_7 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d_3[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 500, 512)     0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 500, 512)     0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 500, 512)     0           ['dropout_7[0][0]',              \n",
      "                                                                  'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 500, 512)     262656      ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 500, 512)    2048        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 500, 512)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 500, 512)     0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " depthwise_conv1d_4 (DepthwiseC  (None, 500, 512)    7168        ['dropout_8[0][0]']              \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 500, 512)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 500, 512)     0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 500, 512)     0           ['dropout_9[0][0]',              \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 500, 512)     262656      ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 500, 512)    2048        ['conv1d_5[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 500, 512)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 500, 512)     0           ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_5 (DepthwiseC  (None, 500, 512)    7168        ['dropout_10[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_5[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 500, 512)     0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 500, 512)     0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 500, 512)     0           ['dropout_11[0][0]',             \n",
      "                                                                  'dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 500, 512)     262656      ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 500, 512)    2048        ['conv1d_6[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 500, 512)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 500, 512)     0           ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_6 (DepthwiseC  (None, 500, 512)    7168        ['dropout_12[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_6[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 500, 512)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 500, 512)     0           ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 500, 512)     0           ['dropout_13[0][0]',             \n",
      "                                                                  'dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 500, 512)     262656      ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 500, 512)    2048        ['conv1d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 500, 512)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_14 (Dropout)           (None, 500, 512)     0           ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_7 (DepthwiseC  (None, 500, 512)    7168        ['dropout_14[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_7[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 500, 512)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 500, 512)     0           ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 500, 512)     0           ['dropout_15[0][0]',             \n",
      "                                                                  'dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 500, 512)     262656      ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 500, 512)    2048        ['conv1d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 500, 512)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 500, 512)     0           ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_8 (DepthwiseC  (None, 500, 512)    7168        ['dropout_16[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_8[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 500, 512)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 500, 512)     0           ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 500, 512)     0           ['dropout_17[0][0]',             \n",
      "                                                                  'dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 500, 512)     262656      ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 500, 512)    2048        ['conv1d_9[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 500, 512)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 500, 512)     0           ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_9 (DepthwiseC  (None, 500, 512)    7168        ['dropout_18[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_9[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 500, 512)     0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 500, 512)     0           ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 500, 512)     0           ['dropout_19[0][0]',             \n",
      "                                                                  'dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 500, 512)     262656      ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 500, 512)    2048        ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 500, 512)     0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 500, 512)     0           ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['dropout_20[0][0]']             \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            1539        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,758,659\n",
      "Trainable params: 2,737,155\n",
      "Non-trainable params: 21,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_mixer_model = get_conv_mixer_256_8()\n",
    "conv_mixer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d858c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 21:45:55.847682: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2023-09-10 21:45:56.543168: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-09-10 21:45:56.626102: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/758 [==============================] - ETA: 0s - loss: 0.0589 - mse: 0.0589\n",
      "Epoch 1: val_loss improved from inf to 0.02724, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 83s 99ms/step - loss: 0.0589 - mse: 0.0589 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 2/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0455 - mse: 0.0455\n",
      "Epoch 2: val_loss improved from 0.02724 to 0.02179, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 3/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0412 - mse: 0.0412\n",
      "Epoch 3: val_loss did not improve from 0.02179\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0416 - val_mse: 0.0416\n",
      "Epoch 4/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0371 - mse: 0.0371\n",
      "Epoch 4: val_loss improved from 0.02179 to 0.01324, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 5/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0344 - mse: 0.0344\n",
      "Epoch 5: val_loss did not improve from 0.01324\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 6/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0334 - mse: 0.0334\n",
      "Epoch 6: val_loss improved from 0.01324 to 0.01252, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 7/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0292 - mse: 0.0292\n",
      "Epoch 7: val_loss did not improve from 0.01252\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 8/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0263 - mse: 0.0263\n",
      "Epoch 8: val_loss did not improve from 0.01252\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 9/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0235 - mse: 0.0235\n",
      "Epoch 9: val_loss did not improve from 0.01252\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 10/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0196 - mse: 0.0196\n",
      "Epoch 10: val_loss improved from 0.01252 to 0.00945, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 11/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0176 - mse: 0.0176\n",
      "Epoch 11: val_loss did not improve from 0.00945\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 12/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 12: val_loss improved from 0.00945 to 0.00896, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 13/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 13: val_loss improved from 0.00896 to 0.00808, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 14/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0140 - mse: 0.0140\n",
      "Epoch 14: val_loss improved from 0.00808 to 0.00733, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 15/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 15: val_loss did not improve from 0.00733\n",
      "758/758 [==============================] - 73s 96ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 16/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0113 - mse: 0.0113\n",
      "Epoch 16: val_loss improved from 0.00733 to 0.00681, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 95ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 17/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 17: val_loss improved from 0.00681 to 0.00624, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 18/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 18: val_loss did not improve from 0.00624\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 19/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 19: val_loss did not improve from 0.00624\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 20/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 20: val_loss improved from 0.00624 to 0.00558, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 21/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 21: val_loss did not improve from 0.00558\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 22/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 22: val_loss did not improve from 0.00558\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 23/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 23: val_loss improved from 0.00558 to 0.00537, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 94ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 24/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 24: val_loss did not improve from 0.00537\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 25/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 25: val_loss did not improve from 0.00537\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 26/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 26: val_loss improved from 0.00537 to 0.00528, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 27/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 27: val_loss improved from 0.00528 to 0.00466, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 94ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 28/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 28: val_loss did not improve from 0.00466\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 29/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 29: val_loss improved from 0.00466 to 0.00466, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0047 - val_mse: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 30: val_loss improved from 0.00466 to 0.00442, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 94ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 31/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 31: val_loss did not improve from 0.00442\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 32/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 32: val_loss improved from 0.00442 to 0.00430, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 33/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 33: val_loss did not improve from 0.00430\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 34/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 34: val_loss improved from 0.00430 to 0.00417, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 35/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 35: val_loss improved from 0.00417 to 0.00368, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 36/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 36: val_loss did not improve from 0.00368\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 37/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 37: val_loss did not improve from 0.00368\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 38/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 38: val_loss did not improve from 0.00368\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 39/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 39: val_loss improved from 0.00368 to 0.00340, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 94ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 40/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 40: val_loss did not improve from 0.00340\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 41/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 41: val_loss did not improve from 0.00340\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 42/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 42: val_loss did not improve from 0.00340\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 43/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 43: val_loss did not improve from 0.00340\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 44/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 44: val_loss did not improve from 0.00340\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 45/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 45: val_loss improved from 0.00340 to 0.00339, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 95ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 46/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 46: val_loss did not improve from 0.00339\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 47/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 47: val_loss improved from 0.00339 to 0.00335, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 94ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 48/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 48: val_loss did not improve from 0.00335\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 49/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 49: val_loss improved from 0.00335 to 0.00325, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 94ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 50/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 50: val_loss did not improve from 0.00325\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 51/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 51: val_loss did not improve from 0.00325\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 52/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 52: val_loss did not improve from 0.00325\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 53/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 53: val_loss did not improve from 0.00325\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 54/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 54: val_loss improved from 0.00325 to 0.00302, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 55/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 55: val_loss did not improve from 0.00302\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 56/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 56: val_loss did not improve from 0.00302\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 57/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 57: val_loss did not improve from 0.00302\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 58/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 58: val_loss did not improve from 0.00302\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 59/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 59: val_loss did not improve from 0.00302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 60/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 60: val_loss did not improve from 0.00302\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 61/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 61: val_loss improved from 0.00302 to 0.00299, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 62/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 62: val_loss did not improve from 0.00299\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 63/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 63: val_loss did not improve from 0.00299\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 64/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 64: val_loss did not improve from 0.00299\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 65/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 65: val_loss did not improve from 0.00299\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 66/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 66: val_loss did not improve from 0.00299\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 67/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 67: val_loss improved from 0.00299 to 0.00297, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 68/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 68: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 69/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 69: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 70/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 70: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 71/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 71: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 72/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 72: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 73/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 73: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 74/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 74: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 75/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 75: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 76/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 76: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 77/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 77: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 78/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 78: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 79/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 79: val_loss did not improve from 0.00297\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 80/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 80: val_loss improved from 0.00297 to 0.00289, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 94ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 81/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 81: val_loss improved from 0.00289 to 0.00278, saving model to TX_bestmodelConvMix3.h5\n",
      "758/758 [==============================] - 72s 95ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 82/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 82: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 83/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 83: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 84/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 84: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 85/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 85: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 86/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 86: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 87/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 87: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 88/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 88: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 89/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 89: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0031 - val_mse: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 90: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 91/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 91: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 92/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 92: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 93/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 93: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 94/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 94: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 95/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 95: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 96/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 96: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 97/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 97: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 98/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 98: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 99/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 99: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 100/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 100: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 101/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 101: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 102/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 102: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 103/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 103: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 104/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 104: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 105/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 105: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 106/300\n",
      "758/758 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 106: val_loss did not improve from 0.00278\n",
      "758/758 [==============================] - 71s 94ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0033 - val_mse: 0.0033\n"
     ]
    }
   ],
   "source": [
    "history, conv_mixer_model = run_experiment(conv_mixer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0382579f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = get_conv_mixer_256_8()\n",
    "\n",
    "#checkpoint_filepath = \"/tmp/checkpoint_ct40\"\n",
    "model1.load_weights('TX_bestmodelConvMix3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a01bc4ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 12:05:57.449394: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2023-09-17 12:05:58.814538: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-09-17 12:05:58.865562: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 6s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "ix = int(len(data)*0.9)\n",
    "#out = vit_classifier.predict(italy_data_resized[ix:],verbose=1)\n",
    "\n",
    "out = model1.predict(data[ix:],verbose=1)\n",
    "denormalized_d1 = out[:,2] * (max_d - min_d) + min_d\n",
    "\n",
    "#np.save('out_conv_mixer_Valid',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94e8328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count ')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 18}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "fig = plt.figure()\n",
    "fig_size = plt.gcf().get_size_inches()\n",
    "#plt.gcf().set_size_inches(fig_size * [1.5, 1])\n",
    "\n",
    "bins = np.linspace(0.1, 60.74, 400)\n",
    "diff3 = np.abs(denormalized_d1 - relative_list[ix:,2])\n",
    "np.save('err_dep',diff3)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.hist(diff3,bins, color='red', alpha=0.6,edgecolor='black',linewidth=1.2)\n",
    "plt.xlim([0, 10])\n",
    "#plt.ylim([-3, 3])\n",
    "#plt.yticks(np.arange(-3, 3, 0.5))\n",
    "plt.xticks(np.arange(0, 10.1, 1))\n",
    "plt.ylim(0, 200)\n",
    "\n",
    "\n",
    "plt.title('Depth',fontsize='large', fontweight='bold')\n",
    "plt.xlabel('prediction error (km)',fontsize='large', fontweight='bold')\n",
    "plt.ylabel('Count ',fontsize='large', fontweight='bold')\n",
    "\n",
    "#fig.savefig('Fig3(g).pdf', bbox_inches='tight', transpernt=True, dpi=100)\n",
    "#fig.savefig('Fig3(g).png', bbox_inches='tight', transpernt=True, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cddcb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the Lat and Long\n",
    "e_stlat1= e_stlat[ix:]\n",
    "e_stlong1= e_stlong[ix:]\n",
    "predict_lat = out[:,0]\n",
    "predict_long = out[:,1]\n",
    "\n",
    "eq_lat = e_stlat1- predict_lat\n",
    "eq_long = e_stlong1- predict_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92fc51be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import obspy\n",
    "c=[]\n",
    "dd = evlat[ix:]\n",
    "dd1 = evlon[ix:]\n",
    "distall=[]\n",
    "for i in range(0,len(dd)):\n",
    "    #mae = np.mean(np.abs(outtest[i]-dd[i]))\n",
    "    #mae1 = np.mean(np.abs(outtest1[i]-dd1[i]))\n",
    "    #if (mae<=0.1) and (mae1<=0.1):\n",
    "    dis = obspy.geodetics.base.gps2dist_azimuth(dd[i],dd1[i],eq_lat[i],eq_long[i])\n",
    "    #print(dis[0]/1000)\n",
    "    distall.append(dis[0]/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ccb8d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count ')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 18}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "fig = plt.figure()\n",
    "fig_size = plt.gcf().get_size_inches()\n",
    "#plt.gcf().set_size_inches(fig_size * [1.5, 1])\n",
    "\n",
    "bins = np.linspace(0.1, 110.6, 500)\n",
    "diff4 = np.array(distall)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.hist(diff4,bins, color='red', alpha=0.6,edgecolor='black',linewidth=1.2)\n",
    "plt.xlim([0, 10])\n",
    "#plt.ylim([-3, 3])\n",
    "#plt.yticks(np.arange(-3, 3, 0.5))\n",
    "plt.xticks(np.arange(0, 10.1, 1))\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.title('Distance',fontsize='large', fontweight='bold')\n",
    "plt.xlabel('prediction error (km)',fontsize='large', fontweight='bold')\n",
    "plt.ylabel('Count ',fontsize='large', fontweight='bold')\n",
    "\n",
    "#fig.savefig('Fig3(h).pdf', bbox_inches='tight', transpernt=True, dpi=100)\n",
    "#fig.savefig('Fig3(h).png', bbox_inches='tight', transpernt=True, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80b2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c03b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17568573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068c9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd3272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-39",
   "language": "python",
   "name": "tf-gpu-39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
