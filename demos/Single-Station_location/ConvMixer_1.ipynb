{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c93954c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#vimport tensorflow_addons as tfa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee768d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13475, 5000, 3), (13475, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# load data\n",
    "data = np.load('loc/datloc.npy')\n",
    "relative_list = np.load('loc/relativelist.npy')\n",
    "e_stlat = np.load('loc/stlat.npy')\n",
    "e_stlong = np.abs(np.load('loc/stlon.npy'))\n",
    "evlat = np.load('loc/evlat.npy')\n",
    "evlon = np.abs(np.load('loc/evlon.npy'))\n",
    "\n",
    "relative_list[:,0] = e_stlat - evlat\n",
    "relative_list[:,1] = e_stlong - evlon\n",
    "relative_list[:,2] = relative_list[:,2]/1000\n",
    "np.shape(data), np.shape(relative_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a700aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Depth\n",
    "d= relative_list[0:,2]\n",
    "min_d = np.min(d)\n",
    "max_d = np.max(d)\n",
    "normalized_d = (d - min_d) / (max_d - min_d)\n",
    "relative_list3 = np.copy(relative_list)\n",
    "relative_list3[:,2] = normalized_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44bee882",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 128\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b04a9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras import constraints\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.keras.layers import DepthwiseConv1D\n",
    "# imports for backwards namespace compatibility\n",
    "# pylint: disable=unused-import\n",
    "# pylint: enable=unused-import\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.util.tf_export import keras_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bf07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout= 0.1\n",
    "def activation_block(x):\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    if dropout != 0.0:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_stem(x, filters: int, patch_size: int):\n",
    "    x = layers.Conv1D(filters, kernel_size=patch_size, strides=patch_size)(x)\n",
    "    return activation_block(x)\n",
    "\n",
    "\n",
    "def conv_mixer_block(x, filters: int, kernel_size: int):\n",
    "    # Depthwise convolution.\n",
    "    x0 = x\n",
    "    x = DepthwiseConv1D(kernel_size=kernel_size, padding=\"same\")(x)\n",
    "    x = layers.Add()([activation_block(x), x0])  # Residual.\n",
    "\n",
    "    # Pointwise convolution.\n",
    "    x = layers.Conv1D(filters, kernel_size=1)(x)\n",
    "    x = activation_block(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def get_conv_mixer_256_8(\n",
    "\n",
    "\n",
    "\n",
    "    image_size=5000, filters=512, depth=10, kernel_size=13, patch_size=10, num_classes=3  #\n",
    "    \n",
    "):\n",
    "    \"\"\"ConvMixer-256/8: https://openreview.net/pdf?id=TVHS5Y4dNvM.\n",
    "    The hyperparameter values are taken from the paper.\n",
    "    \"\"\"\n",
    "    inputs = keras.Input((image_size, 3))\n",
    "    #x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
    "    #x = (inputs)\n",
    "\n",
    "    # Extract patch embeddings.\n",
    "    x = conv_stem(inputs, filters, patch_size)\n",
    "\n",
    "    # ConvMixer blocks.\n",
    "    for _ in range(depth):\n",
    "        x = conv_mixer_block(x, filters, kernel_size)\n",
    "\n",
    "    # Classification block.\n",
    "    x = layers.GlobalAvgPool1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"linear\")(x)\n",
    "\n",
    "    model = tensorflow.keras.Model(inputs, outputs)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f6a0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code reference:\n",
    "# https://keras.io/examples/vision/image_classification_with_vision_transformer/.\n",
    "\n",
    "# Test index\n",
    "ix = int(len(data)*0.9)\n",
    "\n",
    "def run_experiment(model):\n",
    "    \n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tensorflow.keras.optimizers.Adam(lr=0.001),\n",
    "        loss= ['mse'],\n",
    "        metrics= ['mse'],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"TX_bestmodelConvMix4.h5\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\",mode='min',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=25, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        data[0:ix], relative_list3[0:ix], batch_size=16,validation_split=0.0625 ,\n",
    "        epochs=300, shuffle=False,\n",
    "        callbacks=[checkpoint_callback,early_stopping],\n",
    "    )\n",
    "\n",
    "    #model.load_weights(checkpoint_filepath)\n",
    "    #_, accuracy = model.evaluate(test_dataset)\n",
    "    #print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff37903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 21:21:35.022777: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-22 21:21:36.125864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9277 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5000, 3)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 500, 512)     15872       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 500, 512)    2048        ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 500, 512)     0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 500, 512)     0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " depthwise_conv1d (DepthwiseCon  (None, 500, 512)    7168        ['dropout[0][0]']                \n",
      " v1D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 500, 512)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 500, 512)     0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 500, 512)     0           ['dropout_1[0][0]',              \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 500, 512)     262656      ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 500, 512)    2048        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 500, 512)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 500, 512)     0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " depthwise_conv1d_1 (DepthwiseC  (None, 500, 512)    7168        ['dropout_2[0][0]']              \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 500, 512)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 500, 512)     0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 500, 512)     0           ['dropout_3[0][0]',              \n",
      "                                                                  'dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 500, 512)     262656      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 500, 512)    2048        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 500, 512)     0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 500, 512)     0           ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " depthwise_conv1d_2 (DepthwiseC  (None, 500, 512)    7168        ['dropout_4[0][0]']              \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 500, 512)     0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 500, 512)     0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 500, 512)     0           ['dropout_5[0][0]',              \n",
      "                                                                  'dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 500, 512)     262656      ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 500, 512)    2048        ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 500, 512)     0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 500, 512)     0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " depthwise_conv1d_3 (DepthwiseC  (None, 500, 512)    7168        ['dropout_6[0][0]']              \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_7 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d_3[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 500, 512)     0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 500, 512)     0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 500, 512)     0           ['dropout_7[0][0]',              \n",
      "                                                                  'dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 500, 512)     262656      ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 500, 512)    2048        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 500, 512)     0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 500, 512)     0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " depthwise_conv1d_4 (DepthwiseC  (None, 500, 512)    7168        ['dropout_8[0][0]']              \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 500, 512)    2048        ['depthwise_conv1d_4[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 500, 512)     0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 500, 512)     0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 500, 512)     0           ['dropout_9[0][0]',              \n",
      "                                                                  'dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 500, 512)     262656      ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 500, 512)    2048        ['conv1d_5[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 500, 512)     0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 500, 512)     0           ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_5 (DepthwiseC  (None, 500, 512)    7168        ['dropout_10[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_5[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 500, 512)     0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 500, 512)     0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 500, 512)     0           ['dropout_11[0][0]',             \n",
      "                                                                  'dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 500, 512)     262656      ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 500, 512)    2048        ['conv1d_6[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 500, 512)     0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 500, 512)     0           ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_6 (DepthwiseC  (None, 500, 512)    7168        ['dropout_12[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_6[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 500, 512)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 500, 512)     0           ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 500, 512)     0           ['dropout_13[0][0]',             \n",
      "                                                                  'dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 500, 512)     262656      ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 500, 512)    2048        ['conv1d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 500, 512)     0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_14 (Dropout)           (None, 500, 512)     0           ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_7 (DepthwiseC  (None, 500, 512)    7168        ['dropout_14[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_7[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 500, 512)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 500, 512)     0           ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 500, 512)     0           ['dropout_15[0][0]',             \n",
      "                                                                  'dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 500, 512)     262656      ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 500, 512)    2048        ['conv1d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 500, 512)     0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 500, 512)     0           ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_8 (DepthwiseC  (None, 500, 512)    7168        ['dropout_16[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_8[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 500, 512)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 500, 512)     0           ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 500, 512)     0           ['dropout_17[0][0]',             \n",
      "                                                                  'dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 500, 512)     262656      ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 500, 512)    2048        ['conv1d_9[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 500, 512)     0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 500, 512)     0           ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv1d_9 (DepthwiseC  (None, 500, 512)    7168        ['dropout_18[0][0]']             \n",
      " onv1D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 500, 512)    2048        ['depthwise_conv1d_9[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 500, 512)     0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 500, 512)     0           ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 500, 512)     0           ['dropout_19[0][0]',             \n",
      "                                                                  'dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 500, 512)     262656      ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 500, 512)    2048        ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 500, 512)     0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 500, 512)     0           ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['dropout_20[0][0]']             \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            1539        ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,758,659\n",
      "Trainable params: 2,737,155\n",
      "Non-trainable params: 21,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_mixer_model = get_conv_mixer_256_8()\n",
    "conv_mixer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d858c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/tf-gpu-39/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 21:21:44.517007: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201\n",
      "2023-09-22 21:21:45.680169: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-09-22 21:21:45.724938: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711/711 [==============================] - ETA: 0s - loss: 0.0591 - mse: 0.0591\n",
      "Epoch 1: val_loss improved from inf to 0.01398, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 79s 98ms/step - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 2/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0460 - mse: 0.0460\n",
      "Epoch 2: val_loss did not improve from 0.01398\n",
      "711/711 [==============================] - 70s 99ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 3/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0425 - mse: 0.0425\n",
      "Epoch 3: val_loss improved from 0.01398 to 0.01272, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 70s 99ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 4/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0388 - mse: 0.0388\n",
      "Epoch 4: val_loss did not improve from 0.01272\n",
      "711/711 [==============================] - 70s 99ms/step - loss: 0.0388 - mse: 0.0388 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 5/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0347 - mse: 0.0347\n",
      "Epoch 5: val_loss did not improve from 0.01272\n",
      "711/711 [==============================] - 70s 98ms/step - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 6/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0301 - mse: 0.0301\n",
      "Epoch 6: val_loss did not improve from 0.01272\n",
      "711/711 [==============================] - 70s 98ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 7/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0258 - mse: 0.0258\n",
      "Epoch 7: val_loss improved from 0.01272 to 0.01244, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 70s 99ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 8/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0216 - mse: 0.0216\n",
      "Epoch 8: val_loss did not improve from 0.01244\n",
      "711/711 [==============================] - 70s 99ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 9/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0201 - mse: 0.0201\n",
      "Epoch 9: val_loss improved from 0.01244 to 0.00964, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 10/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0213 - mse: 0.0213\n",
      "Epoch 10: val_loss did not improve from 0.00964\n",
      "711/711 [==============================] - 69s 96ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 11/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0189 - mse: 0.0189\n",
      "Epoch 11: val_loss improved from 0.00964 to 0.00746, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 12/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0164 - mse: 0.0164\n",
      "Epoch 12: val_loss did not improve from 0.00746\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 13/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0170 - mse: 0.0170\n",
      "Epoch 13: val_loss did not improve from 0.00746\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 14/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 14: val_loss improved from 0.00746 to 0.00737, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0074 - val_mse: 0.0074\n",
      "Epoch 15/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0158 - mse: 0.0158\n",
      "Epoch 15: val_loss did not improve from 0.00737\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 16/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 16: val_loss improved from 0.00737 to 0.00651, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 17/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 17: val_loss improved from 0.00651 to 0.00585, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 18/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0119 - mse: 0.0119\n",
      "Epoch 18: val_loss improved from 0.00585 to 0.00568, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 19/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 19: val_loss did not improve from 0.00568\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 20/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 20: val_loss did not improve from 0.00568\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 21/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0104 - mse: 0.0104\n",
      "Epoch 21: val_loss did not improve from 0.00568\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 22/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 22: val_loss improved from 0.00568 to 0.00481, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 23/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 23: val_loss did not improve from 0.00481\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 24/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 24: val_loss improved from 0.00481 to 0.00458, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 25/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 25: val_loss did not improve from 0.00458\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 26/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 26: val_loss did not improve from 0.00458\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 27/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 27: val_loss did not improve from 0.00458\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 28/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 28: val_loss did not improve from 0.00458\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 29/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 29: val_loss did not improve from 0.00458\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 30/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711/711 [==============================] - ETA: 0s - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 30: val_loss did not improve from 0.00458\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 31/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 31: val_loss did not improve from 0.00458\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 32/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 32: val_loss improved from 0.00458 to 0.00427, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 98ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 33/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 33: val_loss did not improve from 0.00427\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 34/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 34: val_loss did not improve from 0.00427\n",
      "711/711 [==============================] - 70s 98ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 35/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 35: val_loss did not improve from 0.00427\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 36/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 36: val_loss improved from 0.00427 to 0.00410, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 70s 99ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 37/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 37: val_loss did not improve from 0.00410\n",
      "711/711 [==============================] - 70s 99ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 38/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 38: val_loss did not improve from 0.00410\n",
      "711/711 [==============================] - 70s 99ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 39/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 39: val_loss improved from 0.00410 to 0.00403, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 71s 99ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 40/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 40: val_loss improved from 0.00403 to 0.00364, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 70s 99ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 41/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 41: val_loss did not improve from 0.00364\n",
      "711/711 [==============================] - 70s 98ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 42/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 42: val_loss did not improve from 0.00364\n",
      "711/711 [==============================] - 71s 100ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 43/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 43: val_loss did not improve from 0.00364\n",
      "711/711 [==============================] - 71s 100ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 44/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 44: val_loss did not improve from 0.00364\n",
      "711/711 [==============================] - 71s 99ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 45/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 45: val_loss did not improve from 0.00364\n",
      "711/711 [==============================] - 71s 99ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 46/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 46: val_loss did not improve from 0.00364\n",
      "711/711 [==============================] - 71s 99ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 47/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0036 - mse: 0.0036\n",
      "Epoch 47: val_loss did not improve from 0.00364\n",
      "711/711 [==============================] - 69s 98ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 48/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0033 - mse: 0.0033\n",
      "Epoch 48: val_loss improved from 0.00364 to 0.00352, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 49/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 49: val_loss did not improve from 0.00352\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0032 - mse: 0.0032 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 50/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 50: val_loss did not improve from 0.00352\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 51/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 51: val_loss improved from 0.00352 to 0.00350, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 52/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 52: val_loss improved from 0.00350 to 0.00347, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 53/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 53: val_loss improved from 0.00347 to 0.00340, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 54/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 54: val_loss did not improve from 0.00340\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 55/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 55: val_loss did not improve from 0.00340\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 56/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 56: val_loss did not improve from 0.00340\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 57/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 57: val_loss did not improve from 0.00340\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 58/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 58: val_loss improved from 0.00340 to 0.00297, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 98ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 59/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 59: val_loss did not improve from 0.00297\n",
      "711/711 [==============================] - 69s 98ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0032 - val_mse: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 60: val_loss improved from 0.00297 to 0.00297, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 61/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0028 - mse: 0.0028\n",
      "Epoch 61: val_loss did not improve from 0.00297\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0028 - mse: 0.0028 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 62/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 62: val_loss did not improve from 0.00297\n",
      "711/711 [==============================] - 68s 96ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 63/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 63: val_loss did not improve from 0.00297\n",
      "711/711 [==============================] - 68s 96ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 64/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 64: val_loss improved from 0.00297 to 0.00290, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 65/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 65: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 66/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 66: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 67/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 67: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 68/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 68: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 69/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 69: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 70/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 70: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 71/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 71: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 98ms/step - loss: 0.0024 - mse: 0.0024 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 72/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 72: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 68s 96ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 73/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 73: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 74/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 74: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 75/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 75: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 76/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 76: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 77/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 77: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0022 - mse: 0.0022 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 78/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 78: val_loss did not improve from 0.00290\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 79/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 79: val_loss improved from 0.00290 to 0.00287, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 80/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 80: val_loss did not improve from 0.00287\n",
      "711/711 [==============================] - 69s 96ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 81/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 81: val_loss did not improve from 0.00287\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 82/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 82: val_loss did not improve from 0.00287\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 83/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 83: val_loss did not improve from 0.00287\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 84/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 84: val_loss did not improve from 0.00287\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 85/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 85: val_loss did not improve from 0.00287\n",
      "711/711 [==============================] - 69s 98ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 86/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 86: val_loss improved from 0.00287 to 0.00286, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 87/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 87: val_loss did not improve from 0.00286\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 88/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 88: val_loss did not improve from 0.00286\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 89/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 89: val_loss did not improve from 0.00286\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 90/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711/711 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 90: val_loss did not improve from 0.00286\n",
      "711/711 [==============================] - 68s 96ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 91/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 91: val_loss did not improve from 0.00286\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 92/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 92: val_loss did not improve from 0.00286\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 93/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 93: val_loss did not improve from 0.00286\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 94/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 94: val_loss did not improve from 0.00286\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 95/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 95: val_loss did not improve from 0.00286\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 96/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 96: val_loss improved from 0.00286 to 0.00276, saving model to TX_bestmodelConvMix4.h5\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 97/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 97: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 98ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 98/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 98: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 99/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 99: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 100/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 100: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 101/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 101: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 102/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 102: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 103/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 103: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 104/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 104: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 105/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 105: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 106/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 106: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 107/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 107: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 108/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 108: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 109/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 109: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 110/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 110: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 111/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 111: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 112/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 112: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 113/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 113: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 114/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 114: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 115/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 115: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 68s 96ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 116/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 116: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 68s 96ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 117/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 117: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 118/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 118: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 68s 96ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 119/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 119: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 120/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0012 - mse: 0.0012\n",
      "Epoch 120: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0012 - mse: 0.0012 - val_loss: 0.0028 - val_mse: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/300\n",
      "711/711 [==============================] - ETA: 0s - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 121: val_loss did not improve from 0.00276\n",
      "711/711 [==============================] - 69s 97ms/step - loss: 0.0011 - mse: 0.0011 - val_loss: 0.0029 - val_mse: 0.0029\n"
     ]
    }
   ],
   "source": [
    "history, conv_mixer_model = run_experiment(conv_mixer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0382579f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = get_conv_mixer_256_8()\n",
    "\n",
    "#checkpoint_filepath = \"/tmp/checkpoint_ct40\"\n",
    "model1.load_weights('TX_bestmodelConvMix4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a01bc4ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 2s 29ms/step\n"
     ]
    }
   ],
   "source": [
    "# Test set [ix:]\n",
    "out = model1.predict(data[ix:],verbose=1)\n",
    "denormalized_d1 = out[:,2] * (max_d - min_d) + min_d\n",
    "\n",
    "#np.save('out_conv_mixer_Valid',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f94e8328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count ')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAEuCAYAAADWRfZCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0HklEQVR4nO3de5wcVZn/8c83VyAQEkIgkUuC+BMvrDdQRAQTRGQVUS4qq7tsQMWFlV28oqBcZLmJqLguqwiIrhcMuiLeuGgILLio4KJIQASSADEQIJmEhMlkMvP8/jjVSU2lu6d70t3Tnfm+X69+TdWpU1XP9PTU03Xq1ClFBGZmZp1i1HAHYGZmVg8nLjMz6yhOXGZm1lGcuMzMrKM4cZmZWUdx4jIzs44yZrgDMOtkkor3kwTQCzwLPAU8BNwOfDMinmhxeA0jaREwI5tdHBEzhy8aG+l8xmXWWALGAVOAFwGHAxcCj0q6SFJbfVmUtEhSZK9Fwx2PWS3a6p/IbAvwQ9IXwh2BVwLbZuVjgU8AL5d0eESsH6b4zDqez7jMGigijomIoyLiIFLy+jCwLlflzcA5wxKc2RbCicusSSKiJyK+BBxfWPRhSTsX60uaIeliSfdIWilpnaQlkq6VNLvcPiRdnWvqC0kzJb1D0q3ZNp6VdJukwwvrzc+uz83IFc8obGt+pd9N0ihJJ0q6S9Jzkrok/VTSy2p9f8yGyonLrMki4rvAPbmirYG35+tIeg+wAPgY8HJgIql58XnAMcA8SV+uYXdnAT8CDsq2sS1wIPATSR/ZrF9ko7GkJtGvAfuQfp/tgbcCt0t6QYP2Y1aWE5dZa9xQmN+/NCHpDcC3gG2yoj7gDuAXwNO5dU6R9NFB9jMHeAa4CXi4sOxzkvbJpm8lJZ/ncsufy8pKr1sr7ON5wDuAJcDNwMrcsu2A0weJ0WyzuHOGWWssLszvlJu+EBidTa8EDoiI+wAkTQD+h9TRA+Azkv4zIvIJJ++PwOyIWC5pFHAV8I/ZstHAR4H3RMRZ2fYXsbG58KmIOKbG3+enwDER0ZOdYd1H6k0JcHCN2zAbEicus9Yo27ohaSqwX67oOeAcSflqE3LT2wMHkM50yrkwIpYDRES/pNPZmLgA3lhn3JV8LCJ6sv08JOnPwN9ky6Y3aB9mZTlxmbXG7oX5J7OfM0n3fpVMB44eZFszqyy7Lz8TEX+VtAKYnBXtJGlcRKzbdNWarY6IPxfK8s2F4zBrIl/jMmuNvy3M/2/2U8WKNZhQZVm5J8MOZR/VPFOmrK/B+zCryGdcZk0m6R+AfDfxbuD6bLp47evmiDh0M3a3N3Bvbt/TgUm55csKZ1t+BLp1HJ9xmTWJpPGSPgxcUVj0pYh4EiD7+bvcsjdKOq7MtiZJ+gdJ3xlkt5+UtEO2zijg3wrLf1WY785NT5E0fpDtmw07n3GZNZCkH5C+EE4BXsXGIZ9KbgTOLJSdnpWPyl7flHQWULqONAPYi9QrsHiGVvQy4EFJdwN7Zq+SfuCLhfoPAi/OprcF/iBpQVb3iogoduM3G3ZOXGaNValjRS/wBeDTxXEKI+KXko4Hvkq6mRfg+dmraLAxDr9IGmaqXHPjpyLid4WybzDwZui9shfA/EH2ZTYs3FRo1lilx5qsIJ3N/Jx0RjUjIj5ZaXDdiPgW6cznQuAuoIvU4WE18ABwDfAB4NWD7P/LpPEQ55EerfIc6bEqb4+Iz5XZ74+B40jNlZXuDTNrK4oY/muzkl4BvJM0TM0MYCqpqeIh4L+BSyJidWGdHYFPAUcAu5H+6e4GLo2In1bYzxHAKaRharYBHiNdJD8/Isr1lDJra5KuZuB9WntExKLhicasNdolcX0V+GCVKguA/SNiVVZ/BnAbm94bU3JmRJxb2Mc5bHptoWQRcFBEPFZP3GbDzYnLRqJ2aipcDlxKGgPtcODa3LKXAKfm5q9kY9L6DXAk6eyrPys7R9IBpcqSDgQ+k832k5pujgTuzMpmsmnPLzMza0Pt0jnju8DHI+LZUoGkn5MuEpfuf3ltVr43G4etCdJ4aY9ny/YE3k+64fJU0kClZNOlmzCviogLsvp3k3ppCThU0ktLY8SZmVl7aoszroi4LZ+0srIgXdwuKV3jyo+1triUtDJ35Kbzzy+alZu+PbePx4BHc8s8OKh1lIiYExHKvRYNd0xmzdYuZ1ybkDSFgUmqNNJAvovwE4XV8vNTJE0inU3tMMg6pdGx96QMSScCJwJstdVW++y+e6VLa63R39/PqFHD/52jHeJohxjaJY52iKFd4miHGNoljnaIAeDBBx98OiKmNmRjEdF2L9II2LeTmgKD9FyiUdmyK3LltxbWOzi3LIBds1e+bHZhndtyy64YLLYXvvCFMdxuueWW4Q4hItojjnaIIaI94miHGCLaI452iCGiPeJohxgiIoC7okE5ou3OuCTtSkpUe2dF84CjI6LU8WJNrnpxeJri/Go2HWC02jqrMTOztjb85485WceL/2Vj0poLvCUGPjTvkdz0tMIm8s8BeiYiuiJiBelm0FrWKT4x1szM2kzbJC5Js0nNg7tmRZcAx0b2sLqcebnp3SXlLzgdlJu+pcL0gbl97kG6eblcPTMza0Nt0VQo6UjSkDalB9B9D7gOOCD3JNi1EXFXRNwr6RZSr0EB10q6gHSvV2lU7SDdE1byZeCobHqOpIdJNzWfnqvzy4j4U0N/MTMza7i2SFykQT7zT039u+yVt5iNT359H6lTxa7Aa4AfFep+NiLy3d5vlXQ+KVGNAs4r1H+UdP+XmZm1ubZpKqxHRCwkjTf4JdJ1qXWkQUnnkQYTPbvMOmeQRsuYl9Vdl637RWDfiBjscRFmZtYG2uKMKyLmAHPqXGcZ6fENH65jnetITZBmZtahOvKMy8zMRi4nLjMz6yhOXGZm1lGcuMzMrKM4cZmZWUdx4jIzs47ixGVmZh3FicvMzDqKE5eZmXUUJy4zM+soTlxmZtZRnLjMzKyjOHGZmVlHceIyM7OO4sRlZmYdxYnLzMw6ihOXmZl1FCcuMzPrKE5cZmbWUZy4zMysozhxmZlZR3HiMjOzjuLEZWZmHcWJy8zMOooTl5mZdRQnLjMz6yhOXGZm1lGcuMzMrKM4cZmZWUdx4jIzs47ixGVmZh3FicvMzDqKE5eZmXUUJy4zM+soTlxmZtZRnLjMzKyjOHGZmVlHceIyM7OO4sRlZmYdZcxwB9DJuru76enpGVA2fvx4tt5662GKyMxsy+fENUTd3d2ccfLJrFm6dED5hOnTOe+yywYkLyc4M7PGaYvEJelU4ABgX2BmbtHxEXF1oe7VwD9W2dzdEbFvmX0cAZwC7ANsAzwGXA+cHxHP1BtzT08Pa5Yu5YwpU5g4diwAq3p7OW/pUnp6ejYkpXoSnJmZDa4tEhdwNrB9szYu6RzgzELxC4CPAEdJOigiHhvKtieOHcuk8eMrLq81wZmZWW3aJXHdCzwI3EVKYjvVuN47gScKZc/mZyQdCHwmm+0HPg3cD5wGvJZ0hncF8Ob6w67dYAnOzMxq0xaJKyIOLE1LOq2OVe+KiEWD1DkVUDZ9VURckO3nbmBxtuxQSS+NiPvq2LeZmQ2DTu8Of5ukdZJWSrpD0omSir/TrNz07aWJrGnw0dyyg5sYZ026u7vp6uoa8Oru7h7usMzM2ooiYrhjGEDSImBGNjuUzhn/DRwTESFpMrA8t+ywiLgxt607gf2y2Usj4tQKMZ0InAgwderUfebOnUtfXx9LHnmEXcaOZfSolCv7+vtZ0tvLLs9/PqNHj05lNdaLCJYsXkx/b++AfY8aO5ZdZsxA0oay1atXs+2221Z5C1qjHeJohxjaJY52iKFd4miHGNoljnaIAWD27NllO84NRVs0FdZpJfAdYB6pZ+COwIeA12XLjyJd+5oLTCisu67KfMW/bERcDlwOsNdee8WsWbPo6upi7sUXc9G0aRuuXXX19DD3iSe46JprmDRpUiqro941F120aSeOZ54ZUA9g/vz5zJo1q/q71ALtEEc7xNAucbRDDO0SRzvE0C5xtEMMjdZxiSsi/rVYJulHpA4XM7Oit5ES15pC1WLviPz86gaFuFncicPMrLqOS1zlRMTarLPFzKxo56x8haQVwOSsfFph1em56YebGmTB+r4+Vq5cuWF+5cqV9PX1tTIEM7OO1FGJS9JEYNeIWFAo34p0Y3HJX3PTt5CaDwEOBK7O1tkD2K1QryW616/nvgULOOeEExibNQv29Pay8IEHWL/zzuAzLjOzitoicUk6lDSaBbmfAK+S1JVN3066DnWvpBuAH5POkqaSrnHNzK13bW76y2xMXHMkPQwsAE7P1fllRPxp83+T2qzr72dMTw+fmjyZqdlF08fWrOGknh76+vtbFYaZWUdqi8RF6vgwo0z5KdkLYDawiNSF/y3Zq5zLIuJnpZmIuFXS+aRENQo4r1D/UeD9Q468oJ4mwInjxm24nrVyXbHfiJmZldMuiatWS4BjgcNJTYPTgO2Ap4HfAV+PiJ8UV4qIMyT9jpQEX8XAsQoviIinGhGcmwDNzJqvLRJXRMyso/r3s1e9+7gOuK7e9erhJkAzs+Zri8S1pXEToJlZ83T6kE9mZjbCOHGZmVlHceIyM7OO4sRlZmYdxYnLzMw6ihOXmZl1FCcuMzPrKE5cZmbWUZy4zMysozhxmZlZR3HiMjOzjuLEZWZmHcWJy8zMOooTl5mZdZSaH2si6aBs8qmIuL9J8ZiZmVVVzxnXfOAW4JxKFSRdKWmZpCc3NzAzM7NyGv0gyYnAjkA0eLtmZmZA469xbdfg7ZmZmQ1Q9YxL0nFlimdUKN8FeEM23be5gZmZmZUzWFPh1Qxs9hOwL/CNCvWV/Vy2eWGZmZmVV+s1LlWYzgs2JrmbhxyRmZlZFbVc46qUqMrVE3AP8MmhBmRmZlbNYGdcx2c/BVxFOqO6C7isUC+AbuDBiPhDQyM0MzPLqZq4IuKbpWlJV5ES2OJ8uZmZWSvVcx/X7OznU80IxMzMrBY1J66IuLWZgZiZmdWirpEzJI0BjgUOBqYD4ytUjYh442bGZmZmtol6BtndAfgl8PLBquIhn8zMrEnqGfLpAuAV1N493szMrOHqaSp8GxvPpJy8zMxsWNRzxrVD9nM9cBwwBRgTEaPKvEY3PFIzMzPqS1xLsp93RMS3I2JFRPQ3IygzM7NK6klcPyY1Ee7YpFjMzMwGVU/iOhd4DHippE9KavSzvMzMzAZVT+eMS4DFwG7AecBJku4BnilTNyLifZsfnq3v62PlypUDyvr6+uju7mbrrbcepqjMzIZPPYlrDhsfXSJSAtu1TL3SfVxOXJupe/167luwgHNOOIGxY8duKD/g6KM549vf5rzLLnPyMrMRp66RM3J8g3ELrOvvZ0xPD5+aPJmp2267ofy3Y8awZulSenp6nLjMbMSpN3H5/q1hMHHcOCaN3zi61mj5z2BmI1c9iWuPpkVhZmZWo5p7BkbE4npe9QQh6VRJ10paKClyrzkV6u8o6RJJf5G0VtJySTdLOrzKPo7I6izP1vlLto0p9cRqZmbDa6jXuBrtbGD7WipKmgHcBuyeKx4PHAIcIunMiDi3sM45wJmFTb0A+AhwlKSDIuKxIcZuZmYtVM/o8LsPXmujiHi0jur3Ag8Cd5GS2E5V6l7JxqT1G+BC4EWkLvqjgHMkzYuIO7K4DwQ+k9XvBz4N3A+cBrwWmAlcAby5jnjNzGyY1HPGtYjaexNGPduOiANL05JOq1RP0t5A6TlfARwTEY9ny/YE3k/qQHIqcEdW71Q2diq5KiIuyOrfTbovTcChkl4aEffVGrOZmQ2PoYx+oRpfzZB/OOXiUtLK3JGbnp2bnpWbvr00kTUN5s8KD25EgGZm1lyKqO0kSlI/G28+LspvRKSRM4Y0QrykRcCMbPb4iLg6t+xS4F+y2TsjYv/cssOAX+Q2NTmLZXmu7LCIuDG3zp3AftnspRFxaoWYTgROBJg6deo+c+fOpa+vjyWPPMIuY8cyelTK/+v6+li4ahV7TpzImNGjm1IG8OyECaxYvpxdnv98Ro8evoH4V69ezba5+8tGagztEkc7xNAucbRDDO0SRzvEADB79uy7I2LfRmyrnqbCb1Yo3xl4Fem6VAA3A3/dzLgqmZCbXldYVpwv95eqtk7Fv2xEXA5cDrDXXnvFrFmz6OrqYu7FF3PRtGkb7rFa/OyzfPamm/jhoYey83bbNaUM4Ff7789Pf/hDLrrmGiZNmlQp7KabP38+s2bNGrb9t0sM7RJHO8TQLnG0QwztEkc7xNBo9VyHOr7SMknjgS8BHyR1nDh6syMrb01uenxhWXF+NZueHVZbZ/VmxGVmZi3SkBHeI6IH+BApsbwQOKMR2y3jkdz0tMKy6bnpZyKiKyJWACtqXOfhBsRnZmZN1rBHk0REH7CKdJbzzkZtt2Bebnr3Qhf9g3LTt1SYzvde3IM0UHC5emZm1qY2+wbk7LlcU0hd0UtnMOVGja+2jUOBbbLZbXKLXiWpK5u+PSLulXQLqdeggGslXQC8BDguqxfApbltfBk4KpueI+lhYAFweq7OLyPiT/XEbGZmw6OeG5D76thuuWd0VXM5G3sS5p2SvSAlq/mkx6XcRkqOrwF+VFjnsxGR7/Z+q6TzSYlqFOlG5bxHSUnXzMw6QD1NhbXcu1V6Xtf1jQ1zo4hYCOxD6gzyMKlnYBepGfHtEXF2mXXOAI7M6nRl6zwMfBHYt96xFc3MbPjU21RY6T6uEgF/YGAz3OAbjZhZZ/1lwIezV63rXAdcV89+zMys/dSTuG6j8pBP64ClwK+AayKid3MDMzMzK6ee+7hmNTEOMzOzmjSsO7yZmVkrDKk7fDYu4FtJjwSBNMr6zyLiFxVXMjMza4C6Elf2tOAfMPBm35KTJN0OHB0RTzciODMzs6KamwoljSZ1c38D5XsWCng9cH1W18zMrOHqucb1d8D+bLxXq9w9XCI9JuQ9jQ3TzMwsqTdxlSwkDao7K3v9MwMHwD12cwMzMzMrp55rXK/Mfq4EXh8RT+SW3SbpOuA+YBLp+VxmZmYNV88Z1xRSc+DvCkkLgIhYCvwum92hAbGZmZltop7EtTb7WXymVV5p2doqdczMzIasnsS1iNT5Ym9JH88eZwKAko8Cf0M6K1vUyCDNzMxK6rnGNY+UmAAuBE6VdH82/yIGPk04/8BHMzOzhqkncX0F+CdgHOnMazobmwbz93WtA/6jIdGZmZkV1NxUGBEPk7rAR+61YXHu579ExEMNi9DMzCynrkF2I+JK4G+B37PpDch3A2+JiK83OkgzM7OSugfZjYibgZslTSU3yG72cEczM7OmGtLo8AAR8RTwVANjMTMzG1TFxCVpLHAaqTmxD/hcpScbSxoHfBwYDfQDF0bE+saHayXr+/pYuXLlgLLx48ez9dZbD1NEZmatUe2M6x3AZ0kdLr5WKWkBRMQ6SbuQeh0G8ADp8SfWBP0R3LdgAeeccAJjx47dUD5h+nTOu+wyJy8z26JVS1xvy01fUsO2LiYlLoAjcOJqmgDG9PTwqcmTmbrttgCs6u3lvKVL6enpceIysy1atcS1b/bzL1lX+KoiYqGkB0g3I+87WH3bfBPHjWPS+PHDHYaZWUtV6w6/G+nLfT33ZJUebbLbkCMyMzOrolriGldDnaLSCBrjqtYyMzMbompJqYuUiP6mSp2il2c/V1atZWZmNkTVEtei7OfzJL1nsA1Jei/wPFLz4sLND83MzGxT1RLXbdlPAZdLOrJSRUlHAV8rs66ZmVlDVetVeDXwkWx6G+AHkv4PuAF4lHRmNQM4DHglA0eIv7rRgZqZmUGVxBUR90n6LvBeUpIS8CpSksorJazSCPHfiYj7Gh2omZkZDN5j8CTgj6TkVHqUSXFU+Hz5H7J1zMzMmqJq4oqI1cDrgblsTFQw8HlcpfLvAwdFxJrmhGpmZlbD6PBZ8jpW0gXAu4D9gZ2zxU8CdwJzI+KeZgVptfHAu2Y2EtT8WJOI+AOpKdDaUPf69R5418xGhCE/j8vay7r+fg+8a2YjghPXFsYD75rZlq6ecQjNzMyGnROXmZl1FCcuMzPrKE5cZmbWUZy4zMyso3Rk4pI0U1IM8jq8sM6Oki6R9BdJayUtl3RzsZ6ZmbW3EdEdXtIM0qNWds8VjwcOAQ6RdGZEnDsswZmZWV22hMT1C+D8MuX5EeqvZGPS+g1wIfAi4DzSWec5kuZFxB3NDNTMzDbflpC4lkXE7ZUWStobeGM2G8AxEfF4tmxP4P2kQYJPBZy4zMzaXEde4yo4QtIKST2SFkm6StILc8vfmJteXEpamXyimt3cMM3MrBEUEYPXajOSZgILq1RZAxwaEb+WdCnwL1n5nRGxf247h5GaGksmR0RXmf2dCJwIMHXq1H3mzp1LX18fSx55hF3GjmX0qJT/1/X1sXDVKvacOJExo0c3pQxg1YQJLH388UHr9vX3s6S3l12e/3xG59ZvlNWrV7NtNi7icGmHGNoljnaIoV3iaIcY2iWOdogBYPbs2XdHxL6N2FanNhUGcA/wQ2ABKVG9DvgYsA0wAbgCeEk2XbKusJ3i/LZA1yY7i7gcuBxgr732ilmzZtHV1cXciy/momnTNowNuPjZZ/nsTTfxw0MPZefttmtKGcBNr30t/3XuuYPW7erpYe4TT3DRNdcwadKkGt7W+syfP59Zs2Y1fLudFkO7xNEOMbRLHO0QQ7vE0Q4xNFpHJq6IWAy8slB8o6SlwH9m8y/OrmHlH2xZHH22OL+6cVGamVkzbAnXuPKKnTR2Bh7JzU8rLJ+em36mXDOhmZm1l45MXJL2kTSuzKLXF+b/CszLze8uKX8v10G56VsaFZ+ZmTVPRzYVAqeQbhz+Dqln4FrgANI1rpK7ImIRgKRbSL0GBVwr6QLS9a/jsroBXNqa0M3MbHN0auIC2AX4RIVly4A5ufn3kUbO2BV4DfCjQv3PVrsXzMzM2kenJq4LgYeBQ4GZwE5AL+l61s+BSyLiqVLliFgoaR/gU8DbgN2A54DfA5dGxPUtjd7MzIasIxNXRDwAnJu9al1nGfDh7GVmZh2qIztnmJnZyOXEZWZmHaUjmwqtduv7+li5cuWAsvHjx7P11lsPU0RmZpvHiWsL1r1+PfctWMA5J5zA2LFjN5RPmD6d8y67zMnLzDqSE9cWbF1/P2N6evjU5MlMzQbZXNXby3lLl9LT0+PEZWYdyYlrBJg4btyGgYAr6e7upqenZ0CZmxTNrB05cRnd3d2ccfLJrFm6dEC5mxTNrB05cRk9PT2sWbqUM6ZMYWJ2LcxNimbWrpy4bIOJY8cO2qRoZjbcfB+XmZl1FCcuMzPrKE5cZmbWUZy4zMysozhxmZlZR3GvwhGoOH7hypUr6evrG8aIzMxq58Q1wpQbv7Cnt5eFDzzA+p13BneHN7M258Q1wpQbv/CxNWs4qaeHvv7+YY7OzGxwTlwjVH78wpXr1g1zNGZmtXPnDDMz6yhOXGZm1lGcuMzMrKM4cZmZWUdx4jIzs47ixGVmZh3F3eGtouIIGwDjx4/3gyXNbFg5cVlZ5UbYAJgwfTrnXXbZgOTV3d1NT0/PgPWd4MysWZy4rKxyI2ys6u3lvKVL6enp2ZCUuru7OePkk1mzdOmA9cslODOzRnDisqryI2yU09PTw5qlSzljyhQmZmdm5RKcmVmjOHFZXfLXvfqy6b6+PiaOHVs1wZmZNYoTl9WseN3rgKOP5r/OP98jy5tZS7k7vNUsf93romnT2GXsWD66ww70eWR5M2shJy6rW+m61+hRozZc1zIzaxUnLjMz6yhOXGZm1lGcuMzMrKO4V6E1RTOGiyo3QkdEDHl7ZtaZnLis4eoZLqrmbVYYoePAY4+lu7vbNzqbjSBOXNZwlYaLOufxx1m2bBnbb7/9hrr9/f2MGrVpi3Xx7KzSCB3ze3s9QofZCOPEZU2THy6q3FnY+r4+/rxwIS/aYw9Gjx49YN3xU6fyqc99bkNCqjRCR2TLBqzbggF+i82WfX19PvMzaxEnLmuJcmdhj61Zw0ldXZy2/fYbygCWdXdz3Lx5nPH3f78hyfX09m4yQkf3+vV0d3c3tEmyFuWaLQ84+mjO+Pa3PbCwWQs4cVlL5c/CVq5bt0lZqbxskiuM0LGuvx9FDLlJstyZWS2PaCnXbPnbMWNYU8fAwn4UjNnQjbjEJekI4BRgH2Ab4DHgeuD8iHhmOGOzgcolucHq1dMkWTwzq/cRLflmy9FSzb+XHwVjtnlGVOKSdA5wZqH4BcBHgKMkHRQRj7U+MmuUWpskyz16ZXMf0VLrLQD17KfWM7Pu7m76+vro6uqqWq9WPiO0djZiEpekA4HPZLP9wKeB+4HTgNcCM4ErgDcPR3zWWLU0SVZcdwiPaOmPKHsLQLGTCVTuaFJU65lZqd4rXvc65l58ccV61faTT1Ld3d1c8IlP0PPUU1X3W0lEDEigJU581igjJnEBpwKl9pyrIuICAEl3A4uzZYdKemlE3Dc8IVorFc+QSgllKPUCNjnTK9fJBMp3NKm0n1WPP86ZO+004MyseA2vVG/amDFcNG1axXqw6bW+ckmqFN83Xv96dsgSTa1nnt3d3SxZvJhrLrpok2VDTaQw9OuR9eyj1uugzdBu8bS7kZS4ZuWmby9NRMRjkh4FZmRFBwM1J65Vvb2bTK9at47x2Yew0WUAfdloEc3cTy1lff39Tfn9WvG7LOvu3uQMqXTAXr7DDhtiqbVeX5kRPHqyZssPbbstUyZM2FC+ZM0aPtHTw4q1axkzZsyg+1m/ww6Qla0tcw2vVI9cDOXqlbvWV1r30v32Y/JWWw2Ir5icyzWFFq1cuZK+3l5O2W47tssl62d7e/limURa1N3dzYWnncbaZcsGlBfPXAerV2w2HWwfla6Dljtjrke1OFoVTy0xdBqNhCFzJE0GlueKDouIG3PL7wT2y2YvjYhTC+ufCJyYze4N/Kl50dZkR+DpYY4B2iOOdogB2iOOdogB2iOOdogB2iOOdogBYK+I2K4RGxopZ1wTCvPFLmr5+W0Ly4iIy4HLASTdFRH7Nja8+rRDDO0SRzvE0C5xtEMM7RJHO8TQLnG0QwylOBq1rZEyOvyawnzxinh+fnWTYzEzs80wIhJXRKwAVuSKphWqTM9NP9z8iMzMbKhGROLK3JKbPrA0IWkPYLcK9cq5vJFBDVE7xADtEUc7xADtEUc7xADtEUc7xADtEUc7xAANjGNEdM4AkPQGYH4220+6p2sBcDrw6qz8lxHxptZHZ2ZmtRoxiQtA0nmkRFXOo8BBEbG4hSGZmVmdRlTiApD0DtJYha9i4FiFF0TEU1VWNTOzNjDiEpeZmXW2kdQ5Y8gkHSHpZknLJa2V9BdJl0ia0qL9nyrpWkkLJUXuNacV+89ieIWk8yT9j6RHJXVLWiPpD5LOkrTJ/W9NiGF3SV+X9HtJT0rqlfScpAclfUPSy5odQ4W4/rbwd1nUgn3OLOyz3OvwZseRxbJV9hn9taQV2f/Io5JukPR3Ldj//Brei5A0s8lxzJD0FUkPZP8b6yU9JekWSSdIdTxCYPNj2VHS5yTdn/2vrpZ0l6R/lTR28C3UvJ+6jk1ZXJdkx9C12TH15ro/qxHhV5UXcA5pKLpyr4XAbi2IoavC/ue08H34apX3IUjDZE1scgyzBolhLbB/iz8fU4ClhTgWtWC/Mwd5LwI4vAVxTAfuqRLDD1oQw/wa3osAdmliDDOAZwbZ/2Ut+kw+H1hSJY5fAuMatK+aj03Ze7S4SlyfqXW/PuOqosyI8qcDRwJ3ZmUzSSPKN9u9wFXAycCyQeo203LgUuAdwOHAtbllLyENZNxMq4HvkYbfeitpJP9zgfXZ8vHAh5ocQ9HXSPcFrm3xfvN+QbrFo/i6o5k7zc4gvg+8PCu6F/gn4E3AUaQnMPyumTFkTqH87//TXJ1fR8SSJsbwAaA0eOUq4ATS5/MnuTontqJlAvhP4HnZ9D2k/9d3AQ9lZW+kcie1etVzbLoS2D2b/g3pWPop0rEV4BxJB9S011Z8A+jUF/BDNn4b+HqufLfszS4te2kLY1pElW81TdzvQcB2hTIBf8jF8/Nh+jv9OBfDT1q43+OyfXaRnvM2XGdcVw/T+/7WXAwLgG2GI44KsW1PSiCl+I5s8v6+ktvXD3Ll+zLwrGL7JscxAejL7W92btl7cuVPA2MavO+KxybSGK+lZf3ArrllX88tu7aWffmMq7pZuekBI8qTus+XHNyqgIZLRNwWEc8WygJ4MFfU0uGyJG0r6c1A/lvajZXqN3jfuwNfzmY/xMDPQ6sdkV1b6pG0SNJVkl7Ygv0elZv+PfBfkpZm1x3vknRcC2Ko5ESgNKDrX0hfbprpptz0myQdL+lNDHxw7U8iovrw+ptvIgP7LuSHu8v/f04BWnlN+I256cUR8XhuPt8yMLuWjTlxVaA0ovwOuaInClXy83s2P6L2k3VOyX8gr2/Rfr8kKYBngRtI/4RPA2cBl7Vg/wK+SfpWPzcivt3sfQ5iMjAJGEe6jnA88HtJr2vyfvMHvveSEtk0YGtgH+Cbki5scgybkDQG+Jdc0Rcjor9S/UaIiOuBD5Oa0yeSms9uAt5GGsT7fODdzYwhs4x0ra3ko5KmSJpGalLNm9mCeEqen5uudiydImnSYBtz4qpss0aU39JJ2p70LXZyVnQD8N3hiwhI17hGD1pr832UdDb+V+CkFuyvnCBdv/gMcDRwGPBZ4Lls+QSaf/11UmH+cuBvGTi0zyckvaTJcRS9G9g1m34auLpF+32c1CmiaBzpGlPTR2iPiD7gvFzRu0jvwVLgkEL1rZodT07+eFrtWAo1HE9HymNNhsIjylcgaVdSh4C9s6J5wNHN/labcynwA9KB89XAR0jPHDod2Il0obwpJO0C/BspcRwfEcsHWaUpIo3w8spC8Y2SlpIuzgO8WNKeEdGsgaPzHVL+CpwUEf2SSmca00nXQQ8jXQNrlY/mpi+LiO5m7zDr9l/64vYX4BhSZ4hjSInzBcAvJO0Vze0kQkR8UVIv6UvNTrlFPyJ1GNkmm1/RzDgK8sfTasdSqOF46jOuCsIjypclaW/gf9mYtOYCb4mI5yqv1VgRsTAibo+In0bEWQw8UB0vqfiP0EhTSf9oIiWKyJotv5GrMyMrv66JcVRye2F+5ybuKz882qOlLy7Zz/yy7ZsYwwCSDmZjQl8L/EeLdn1ybvqyiPhjRDwXEd8idWCCdNbRknvrIuIrpGPUi0lnejsA/8rGpEUurlZ4JDdd7Vj6TER0DbYxJ67qbslNb86I8lsESbNJB8ZSM8wlwLER0dOi/W9TYVH+TG806RrDFk3SPpLGlVn0+sL8X5sYxq256d0ljQLIfu6eW9bK8T/zX2K+FRGtun1kam56w+cvux6a/zy2LIlHRH9EPBARd2dfxPMdRe6MiGZ+Norm5aZ3zzo3lRyUm67pWOqmwuq+zMaeU3MkPczGEeVLfhkRf2pmEJIOZeM3pfzB+1WSurLp2yOiaY/nlnQkcA2pvR7S/VTXAQfkBgRYGxENe8ppGfMlPU66gXIRqbluX+DjuTqPRHPHnFxCughf9BqgNErECtL1pmaeiZ8CHCLpO6ReWWtJvSs/lqtzV0QsamIM3yTdqzWRdN/Qf2Rnme9g431Eqxl4L1PTSHox6RobpM/GF1qx38wfgL2y6Q9LWkY6yziagR0Tmn5fW+7+0//OYtgBOBZ4e1aldE9qI/ZV67HpXkm3kHoNCrhW0gWk+z9LvU+DdBlgcM28p2BLeJEudFa603sxMKMFMSyqEkPpNavJMVxdQwyLmhzDPYPsfzW5+1Za/DmZ06r3oca/x5O04P5C0oG5t0IMvaQz8lb9DfL3A/24xX//F5N6FFb7mzR9FJEslllVYlgPfKCB+6r52ATsQRrUvFK9s2vdr5sKBxERZ5Du8J5HutF0Hemb9BeBfcOPQWmlS0kXmB8hdYXvA1YCdwMXAy+JiBHRbAtcSGr6uZ3Um20d6QL4vcBFwN4RcV+zg4iIHwKvJXWWWUY6MC7L5vePiGuaHQOApJ2Av88Vfb4V+y2JiPuBVwD/TmqVeY70+VxOalL9IK3pDg9pKLpvkzqJrCZ9NhaTrsO+IiK+3qI4BoiIhaTbJL5EOoauIx1T5wFvj4iza92WR4c3M7OO4jMuMzPrKE5cZmbWUZy4zMysozhxmZlZR3HiMjOzjuLEZWZmHcWJy8zMOooTl7UVSbNKA9dmr7MLy+fnl7dLXNZ5JE2UtCz3N311YXn+7z1/mMLMx7Nr9rDQkNQtacZwxzRcnLhsRHNCGtHOYOPguDdGRNPHEdwckZ4afHU2uxVphJQRyYPsWqe5lfRgvFZ7Cvhhbr6Vz5eyBsueKfevuaJOSQKfIz1vTsC7JX0+mjuwdVty4rKOEun5W8Ox3/tIDwW0LcM/sfEBho8B84cvlNpFxMOSfk16EgCk5PsPwxjSsHBT4RZE0sxCs9fVknaU9GVJi7P28UclfUnSDmXWv7qw/kxJx0q6Q9KqUlmu/nhJ75d0k6QnJa2TtCKrf6qkravE+m5Jd0paI2m5pJ8UrzFUWG/Qa1ySpks6W9KvJT0jqVfSU5LukvQ5STuU3is2ff7PWYX3YE62zUGbFCWNkfT3kn4maWn2fqySdG/2nr+gQrwDrqVI2kbSWZIekLRW0tOSvpd/7+shaTtJH5F0a7at3uznLyUdL2mTL7CS5hTfB0n7Svpxtm5/7r2p93OztaSTs/0vy96nruzvc56k6WXiKffZnibpq5Iek7Re0tU1vh9jgfflir4XdQ7aKumD2XtQiufPSmdxm3xGs8/FRyXdn/09F0r6rLLnqUl6iaQfZJ/V5yT9RtLbq+z+u7npd0rasZ7YtwitHPrfr+a+gJkMfEzAPNKo0OUeIfAgsHNh/asLdb5dZr2ZWd0ZpGcQVXucwZ+A3cvEeW6F+r2kZ6BVfNQB6ZvxhuVltn0MsGqQuF5R5r2q9JqTbXfWIHFNBX49yLbWAu8rE3PxPftjhfUfB3ao8zPxCgZ/9MRtwKTCenMKdb5PGs273HtTz+fmBcD9g8TTBbx1kM/2Ldn7kS+7usb35A2F9Q6tUC9fZ36u/H2kZ1qVlv2R3P8Shc8ocH2F3/N60oM/15RZ1g+8s0JcexXqHjfcx56WH+uGOwC/GvjHrHwwvjv7R+8ulF9XWL94AColk7uAG0jPeJpJepjkfYV6DwI/JT1WI1/+f8Do3D4OLrOP+4GbSY8oKS47uxDjgINCYdlBbPpsqC7SgXleFn+QDuZTSY/euLVQf0FWXnrNyrY9a5C4biuz35vZNAn1AYcU1i33N3uI9MDM5wrlZ9bxedgRWFpY/4/Z3+kvhfKfFNadUyGuB4CfZ3/vOXV+brYqs99lwI1lyp8j9zwxKn+2l2b7+B1wZY3vy1m59fuByRXqbZK4gOMZmLR+S+HLBJsmriA9auQm0peXfPka0qNgbi/zWXmoQlwiPay0VO+q4T72tPxYN9wB+NXAP2b5f+735Za/jPR8nvzyvXLLiweg5cBrcstHZ68PFuqdXojj9MLy9+SW/byw7Au5Zbux6bfoswvbHnBQKCwrnvFcR+5MgtQ0/k5gt1zZrGr7q6Ue8NbCsoeB5+WWn1ZY/tvCtot/s68Bo7JlBxaWza/j83BBYd335pYJ+Gph+etyy+eUiesDhe2Pr/Nz88+FencC2+fiuaywfO4gn+1vAOOK8dTwvvwkt40lVeoNeN9J15L6cmW3AduVWW9+Yd1fAGOzZR8o83v8Xe7z+ZvCshkVYrsjV+ePw33safXL17i2bA9GxJWlmYj4IwPbxyGdAVXy+Yj4bW79vojoA95WqLdf1kb/A0k/IDXF5L0V0jUgUgIoWQecndv+Y6SDV92UHiT42lzRKtIZQVdu+/0RcW22n0Z6a2H+CxHx19z8JcATuflXZ/GW0w2cFhH9ABHxP6SHZpZscv2nivzfaT1wZO5vdC2wd6F+8ffIuzkKDyCMiJ4KdSt9borbPzciVmZ1gtQ9vTe3/DBJlY5RK4BTImJdDfEU7ZybfqbGdV5GStCleG4GDouIZyuusdG/RUTp9/pNYdlfIuJ7kD6fpDOvvOdV2Oby3PTOFepssdyrcMtW7gm4fyrM71Zl/VsrlO9RmD9ikDhmZj+nAPkOG0siYlWhbjG+Ws0kfWsvuTeftJpsZmH+3vxMRKyX9AAwLVc8g9RMVvRwmbhXAttl0+OpXf7vNAY4epD6M6ssq/RZqKducfvF92mFpCW5etuRPjNPldnW3RGxuo6Y8iblpoufv0om56afBo6KiOdqXDf/f1iMuXhbRTERVvp75+OeXKHOFstnXFu2KFOmMmWVLK1QXs82ACZUWG9z46um3LY7QbkzgL4hbmuof6dyKn0WNrfuUG3OPlbmpicOYf0dgSslja6lcuGLSH9hcRdDk497qNvoWE5cW7ZiUxDASwrz1ZrNiv9kJYty0wHsGhGq8npFVvdpUlNYya6StmOgYny1WsTAZPUySdvXsF4jEtziwvyA9z07wO01yDrNsCg3vRrYapC/0zuqbKvSZ6GeuoO9T9sDuxRirtSUV088Rflm2yk1rvMb0jWtkncBV0hq1BeteuXjfnKYYhg2TlxbthdK2nC/iqS9gfcW6swbwnZ/mpsW8JViApI0StLrJX1d0n6QmswY2Iw0Djgzt86uwMlDiIeIWMbA6wcTgavyyUvJkZLyzaP5RAoDD5y1+llh/sOFe5E+wsBrU3dl8TZb/u+0LfAFSQOaniSNk/RmSdeU7kNqouL79GlJE7M4BPwbMDa3/IbStb4Guzs3PV1SLU1ta0lN4vfkyuYA/9G4sGqTvVcvzhWNuJEznLi2fFdkN3bOI3XdzTcH/SQi/jyEbV5J6g5d8g7g8ezGyx9LuoPUfPE/wPsZeF3r84VtfUzSAkk3ka5vbc7B85MMbFY7ClisdOPtr4AlwH8z8NvqQww86zpe0rxcZ5Otatjvz0g9GkteANwv6WZJfyAN01MSwKdr/5U2y+cZeH3oZNLf6VeSrpf0W9Lf6Qbg3TT/mveVwCO5+f2BhyTdAPwZ+FBuWQ/w2SbFMT83LeA1tayUdSQ5jPSZKTlJ0sWNC60mezHwOt38Fu9/2Dlxbdl+QbrvZh9gNgMTyMOkbu11y3pvHcbAjhQTSb0JjwBex8bOBJBLJhHxK1I37bwXA2/KtvGtocSUbftW0hll/gL49qT7uw6mTI+8iFgO/DhXNJr0Xh2dvQY9mGc94o4ifTHI7/cQUm+0knXASRFxYw2/zmbLzuoOAx7NFe9Iei/eBryagZ+JoV5LqzWebuAtpHu2SqYCbwb+X67sWeBdETGg80YD3cHA5rVDal0xIp4kfVbzvUY/ptYOzvzG3HQP6RaTEcWJa8u2DNiP9M17EenA+Tjw78B+ETHkC9wRsRDYlzSKwM9JF8vXkf6RlgC/InV1f1nWpTu/7unAe0gH+m7SxfKbSAnjG0ONKdv294EXkUbn+A2p2/R60rWSu0nvxaOF1f6R9J4szuoOZb9PkkZBmEP6wvAkqWv3alKvsn8H/iYivjaU7Q9VRPyedC3pVFKz8FOk33Et6TPxc9J9Zns24TaBcvH8mXQD+Cmkm+KfzuJZRbpZ/ULgxRFxfRNj6AWuyBUdW8+1qohYREq2K3LFZ0n6eGMiHFS+uf/aiCjX63KLpvRl0bYE2XhwC3NF34yIOcMTjVn7yq7nPcTG7uaHZK0BbU1pvMv8GeurYwSODu8zLjMbcSI92+rSXNFpwxVLnfJxfn8kJi1w4jKzkes8Nt4E/iZJNXXSGC7ZWeJx2WwPqTPSiOSRM8xsRMpGbemY4ZKys8R6Rk7ZYvkal5mZdRQ3FZqZWUdx4jIzs47ixGVmZh3FicvMzDqKE5eZmXWU/w91MWUy6iYqQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 18}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "fig = plt.figure()\n",
    "fig_size = plt.gcf().get_size_inches()\n",
    "#plt.gcf().set_size_inches(fig_size * [1.5, 1])\n",
    "\n",
    "bins = np.linspace(0.1, 60.74, 400)\n",
    "diff3 = np.abs(denormalized_d1 - relative_list[ix:,2])\n",
    "np.save('err_dep',diff3)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.hist(diff3,bins, color='red', alpha=0.6,edgecolor='black',linewidth=1.2)\n",
    "plt.xlim([0, 10])\n",
    "#plt.ylim([-3, 3])\n",
    "#plt.yticks(np.arange(-3, 3, 0.5))\n",
    "plt.xticks(np.arange(0, 10.1, 1))\n",
    "plt.ylim(0, 200)\n",
    "\n",
    "\n",
    "plt.title('Depth',fontsize='large', fontweight='bold')\n",
    "plt.xlabel('prediction error (km)',fontsize='large', fontweight='bold')\n",
    "plt.ylabel('Count ',fontsize='large', fontweight='bold')\n",
    "\n",
    "#fig.savefig('Fig3(g).pdf', bbox_inches='tight', transpernt=True, dpi=100)\n",
    "#fig.savefig('Fig3(g).png', bbox_inches='tight', transpernt=True, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cddcb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the Lat and Long\n",
    "e_stlat1= e_stlat[ix:]\n",
    "e_stlong1= e_stlong[ix:]\n",
    "predict_lat = out[:,0]\n",
    "predict_long = out[:,1]\n",
    "\n",
    "eq_lat = e_stlat1- predict_lat\n",
    "eq_long = e_stlong1- predict_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92fc51be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import obspy\n",
    "c=[]\n",
    "dd = evlat[ix:]\n",
    "dd1 = evlon[ix:]\n",
    "distall=[]\n",
    "for i in range(0,len(dd)):\n",
    "    #mae = np.mean(np.abs(outtest[i]-dd[i]))\n",
    "    #mae1 = np.mean(np.abs(outtest1[i]-dd1[i]))\n",
    "    #if (mae<=0.1) and (mae1<=0.1):\n",
    "    dis = obspy.geodetics.base.gps2dist_azimuth(dd[i],dd1[i],eq_lat[i],eq_long[i])\n",
    "    #print(dis[0]/1000)\n",
    "    distall.append(dis[0]/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ec4348f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93949715349811869"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(diff3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ccb8d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count ')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 18}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.style.use('seaborn-deep')\n",
    "\n",
    "fig = plt.figure()\n",
    "fig_size = plt.gcf().get_size_inches()\n",
    "#plt.gcf().set_size_inches(fig_size * [1.5, 1])\n",
    "\n",
    "bins = np.linspace(0.1, 110.6, 500)\n",
    "diff4 = np.array(distall)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.hist(diff4,bins, color='red', alpha=0.6,edgecolor='black',linewidth=1.2)\n",
    "plt.xlim([0, 10])\n",
    "#plt.ylim([-3, 3])\n",
    "#plt.yticks(np.arange(-3, 3, 0.5))\n",
    "plt.xticks(np.arange(0, 10.1, 1))\n",
    "plt.ylim(0, 100)\n",
    "\n",
    "plt.title('Distance',fontsize='large', fontweight='bold')\n",
    "plt.xlabel('prediction error (km)',fontsize='large', fontweight='bold')\n",
    "plt.ylabel('Count ',fontsize='large', fontweight='bold')\n",
    "\n",
    "#fig.savefig('Fig3(h).pdf', bbox_inches='tight', transpernt=True, dpi=100)\n",
    "#fig.savefig('Fig3(h).png', bbox_inches='tight', transpernt=True, dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80b2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c03b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17568573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b068c9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cd3272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-39",
   "language": "python",
   "name": "tf-gpu-39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
